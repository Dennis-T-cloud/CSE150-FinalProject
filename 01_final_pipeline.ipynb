{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pipeline.ipynb\n",
    "# Basic imports + plotting style\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from hmm_utils import (\n",
    "    baum_welch_train,\n",
    "    viterbi_decode,\n",
    "    count_num_params,\n",
    "    compute_aic_bic,\n",
    ")\n",
    "\n",
    "# make plots a bit bigger, nothing fancy\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "DATA_PATH = Path(\"data\") / \"clean\" / \"hpi_po_summary_cleaned.xlsx\"   # adjust to your file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FHFA HPI and build a clean time series with log returns.\n",
    "\n",
    "def load_and_preprocess_hpi(filepath):\n",
    "    \"\"\"\n",
    "    Load FHFA HPI data and build a univariate time series.\n",
    "\n",
    "    This function will depend on the exact CSV format.\n",
    "    For now the idea is:\n",
    "      - filter national, seasonally-adjusted, purchase-only HPI\n",
    "      - keep date and index level columns\n",
    "      - compute log-returns as observations\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_excel(filepath)\n",
    "\n",
    "    # TODO: adapt these column names / filters to the actual FHFA schema.\n",
    "    # Example placeholder:\n",
    "    # df = df_raw[df_raw[\"Level\"] == \"National\"]\n",
    "    # df = df[df[\"Seasonally_Adjusted\"] == \"Yes\"]\n",
    "    # df = df[df[\"Index_Type\"] == \"Purchase-Only\"]\n",
    "\n",
    "    # For now, assume the file is already just one series:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # parse date if needed\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.sort_values(\"date\")\n",
    "    else:\n",
    "        # if no date column, just make an integer index as time\n",
    "        df = df.sort_index()\n",
    "\n",
    "    # assume the HPI level is in a column called \"hpi\"\n",
    "    if \"hpi\" not in df.columns:\n",
    "        raise ValueError(\"Please rename your HPI level column to 'hpi' or update this function.\")\n",
    "\n",
    "    # compute log-returns\n",
    "    df[\"log_hpi\"] = np.log(df[\"hpi\"])\n",
    "    df[\"ret\"] = df[\"log_hpi\"].diff()\n",
    "\n",
    "    # drop first NaN return\n",
    "    df = df.dropna(subset=[\"ret\"]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_and_preprocess_hpi(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "axes[0].plot(df[\"date\"], df[\"hpi\"])\n",
    "axes[0].set_title(\"FHFA HPI Level (National, example)\")\n",
    "axes[0].set_ylabel(\"Index level\")\n",
    "\n",
    "axes[1].plot(df[\"date\"], df[\"ret\"])\n",
    "axes[1].set_title(\"Log Returns of HPI\")\n",
    "axes[1].set_ylabel(\"log-return\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to train an HMM for a given K and collect metrics.\n",
    "\n",
    "def train_and_evaluate_hmm_for_k(observations, K, max_iters=100, n_restarts=3, seed=0):\n",
    "    \"\"\"\n",
    "    Train a Gaussian HMM with K states on the given 1D observations.\n",
    "\n",
    "    This wraps:\n",
    "      - Baum-Welch training (from mini-project style code)\n",
    "      - Viterbi decoding\n",
    "      - AIC/BIC calculation\n",
    "\n",
    "    Returns a simple dict storing everything we care about.\n",
    "    \"\"\"\n",
    "    T = len(observations)\n",
    "\n",
    "    best_params, loglik_trace = baum_welch_train(\n",
    "        observations,\n",
    "        K,\n",
    "        max_iters=max_iters,\n",
    "        tol=1e-6,\n",
    "        n_restarts=n_restarts,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    final_loglik = loglik_trace[-1]\n",
    "    num_params = count_num_params(K)\n",
    "    aic, bic = compute_aic_bic(final_loglik, num_params, T)\n",
    "\n",
    "    viterbi_path = viterbi_decode(observations, best_params)\n",
    "\n",
    "    result = {\n",
    "        \"K\": K,\n",
    "        \"params\": best_params,\n",
    "        \"loglik_trace\": loglik_trace,\n",
    "        \"final_loglik\": final_loglik,\n",
    "        \"AIC\": aic,\n",
    "        \"BIC\": bic,\n",
    "        \"viterbi_path\": viterbi_path,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HMMs with K = 2, 3, 4 and store results.\n",
    "\n",
    "observations = df[\"ret\"].values\n",
    "\n",
    "results_by_k = {}\n",
    "\n",
    "for K in [2, 3, 4]:\n",
    "    print(f\"Training HMM with K = {K}...\")\n",
    "    res = train_and_evaluate_hmm_for_k(observations, K, max_iters=100, n_restarts=3, seed=42)\n",
    "    results_by_k[K] = res\n",
    "    print(f\"  final log-likelihood: {res['final_loglik']:.2f}, BIC: {res['BIC']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73158ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log-likelihood vs iteration to see if EM is behaving.\n",
    "\n",
    "plt.figure()\n",
    "for K, res in results_by_k.items():\n",
    "    trace = res[\"loglik_trace\"]\n",
    "    plt.plot(trace, label=f\"K={K}\")\n",
    "plt.xlabel(\"EM iteration\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "plt.title(\"EM convergence for different K\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick comparison of K in tabular form.\n",
    "\n",
    "rows = []\n",
    "for K, res in results_by_k.items():\n",
    "    rows.append(\n",
    "        {\n",
    "            \"K\": K,\n",
    "            \"final_loglik\": res[\"final_loglik\"],\n",
    "            \"AIC\": res[\"AIC\"],\n",
    "            \"BIC\": res[\"BIC\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_k_compare = pd.DataFrame(rows).sort_values(\"K\")\n",
    "df_k_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Viterbi path for K=3 as colored bands under the returns.\n",
    "\n",
    "K_target = 3\n",
    "res_k3 = results_by_k[K_target]\n",
    "path = res_k3[\"viterbi_path\"]\n",
    "\n",
    "# For a chill visualization, we just map states to colors.\n",
    "state_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax1.plot(df[\"date\"], df[\"ret\"], label=\"log-return\")\n",
    "ax1.set_ylabel(\"log-return\")\n",
    "ax1.set_title(f\"HMM regimes (K={K_target}) via Viterbi\")\n",
    "\n",
    "# add regime bands as a background color bar\n",
    "# we draw vertical segments; simple but works\n",
    "for t in range(len(df)):\n",
    "    ax1.axvspan(\n",
    "        df[\"date\"].iloc[t],\n",
    "        df[\"date\"].iloc[t] + pd.Timedelta(\"1D\"),\n",
    "        color=state_colors[path[t]],\n",
    "        alpha=0.08,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8110450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save the key plots and print a short summary for the report.\n",
    "\n",
    "FIG_DIR = Path(\"figures\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Example: save the K comparison table as CSV\n",
    "df_k_compare.to_csv(FIG_DIR / \"k_compare.csv\", index=False)\n",
    "\n",
    "print(\"K comparison summary:\")\n",
    "print(df_k_compare.to_string(index=False))\n",
    "\n",
    "print(\"\\nYou can now copy numbers from this table into your report and\")\n",
    "print(\"use the plots above as figures in the Results section.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
